= Cloud SDK pass:[<br/>] Deserialize Sample pass:[<br/>] Tutorial pass:[<br/>] 
:sectnums:
:sectnumlevels: 1
:author: Copyright 2023 Sony Semiconductor Solutions Corporation
:version-label: Version 
:revnumber: x.x.x
:revdate: YYYY - MM - DD
:trademark-desc1: AITRIOS™ and AITRIOS logos are the registered trademarks or trademarks
:trademark-desc2: of Sony Group Corporation or its affiliated companies.
:toc:
:toc-title: TOC
:toclevels: 1
:chapter-label:
:lang: en

== Change history
[width="100%", cols="23%,77%", options="header"]
|===
|Date |What/Why 

|2022/12/12
|Initial draft

|2023/1/30
|Fixed typos + 
Unified the swinging of expressions + 
Fixed the notation + 
Followed the directory structure change of the "**Edge Application SDK**" + 
Updated the PDF build environment

|2023/5/26
|Upgraded the version of FlatBuffers + 
Added support for Semantic Segmentation

|2023/10/20
|Document fix due to unpublishing of the sample "**Edge Application**" for Semantic Segmentation

|===

== Introduction
This tutorial shows you how to automatically generate code for deserialize using FlatBuffers and how to use the generated code. + 
The following AI models are supported in this tutorial: + 

* Object Detection
* Classification
* Semantic Segmentation

Explains how to use source code generated by Python and TypeScript. + 
For more languages supported by FlatBuffers, see the official page(https://google.github.io/flatbuffers/flatbuffers_support.html[Platform/Language/Feature_support]).

== Terms/Abbreviations
|===
|Terms/Abbreviations |Meaning 

|FlatBuffers
|Google binary serialize format

|FBS file
|File which define data structure for FlatBuffers

|===

== Deserialize Repository Configuration
Operation environment for deserialize-sample is as follows. Omit parts that are not relevant to the implementation.
----
aitrios-sdk-deserialization-sample
├── sample (1)
├── src
│   ├── Python (2)
│   └── TypeScript (3)
----
(1) sample : Folder storing sample code showing how to use the automatically generated code +
(2) Python : Folder storing auto-generated source code for Python +
(3) TypeScript : Folder storing auto-generated source code for TypeScript


----
├── sample
│   ├── Classification_encoded.json (1)
│   ├── ObjectDetection_encoded.json (2)
│   ├── Segmentation_encoded.json (3)
│   ├── Python
│   │   ├── Classification
│   │   │   └── decode.py (4)
│   │   ├── ObjectDetection
│   │   │   └── decode.py (5)
│   │   ├── Segmentation
│   │   │   └── decode.py (6)
│   │   └── requirements.txt
│   └── TypeScript
│       ├── Classification
│       │   └── decode.ts (7)
│       ├── ObjectDetection
│       │    └── decode.ts (8)
│       └── Segmentation
│            └── decode.ts (9)
----
(1) Classification_encoded.json : Input data for deserialize operation check corresponding to Classification +
(2) ObjectDetection_encoded.json : Input data for deserialize operation check corresponding to Object Detection +
(3) Segmentation_encoded : Input data for deserialize operation check corresponding to Semantic Segmentation +
(4) decode.py : Classification : Sample use of auto-generated source code for Python +
(5) decode.py : ObjectDetection : Sample use of auto-generated source code for Python +
(6) decode.py : Segmentation : Sample use of auto-generated source code for Python +
(7) decode.ts : Classification : Sample use of auto-generated source code for TypeScript +
(8) decode.ts : ObjectDetection : Sample use of auto-generated source code for TypeScript +
(9) decode.ts : Segmentation : Sample use of auto-generated source code for TypeScript +



----
├── src
│   └── Python
│       ├── Classification (1)
│       │   └── SmartCamera
│       │       ├── ClassificationData.py
│       │       ├── ClassificationTop.py
│       │       ├── GeneralClassification.py
│       │       └── __init__.py
│       ├── ObjectDetection (2)
│       │   └── SmartCamera
│       │       ├── BoundingBox.py
│       │       ├── BoundingBox2d.py
│       │       ├── GeneralObject.py
│       │       ├── ObjectDetectionData.py
│       │       ├── ObjectDetectionTop.py
│       │       └── __init__.py
│       └── Segmentation (3)
│           └── SmartCamera
│               ├── SemanticSegmentationData.py
│               ├── SemanticSegmentationTop.py
│               └── __init__.py
----
(1) Classification : The folder storing the auto-generated source code for Classification in Python +
(2) ObjectDetection : The folder storing the auto-generated source code for Object Detection in Python +
(3) Segmentation : The folder storing the auto-generated source code for Semantic Segmentation in Python +

----
├── src
│   └── TypeScript
│       ├── Classification (1)
│       │   ├── classification.ts
│       │   ├── smart-camera
│       │   │   ├── classification-data.ts
│       │   │   ├── classification-top.ts
│       │   │   └── general-classification.ts
│       │   └── smart-camera.ts
│       ├── ObjectDetection (2)
│       │   ├── objectdetection.ts
│       │   ├── smart-camera
│       │   │   ├── bounding-box.ts
│       │   │   ├── bounding-box2d.ts
│       │   │   ├── general-object.ts
│       │   │   ├── object-detection-data.ts
│       │   │   └── object-detection-top.ts
│       │   └── smart-camera.ts
│       └── Segmentation (3)
│           ├── semantic_segmentation.ts
│           ├── smart-camera
│           │   ├── semantic-segmentation-data.ts
│           │   └── semantic-segmentation-top.ts
│           └── smart-camera.ts
----
(1) Classification : The folder storing the auto-generated source code for Classification in TypeScript +
(2) ObjectDetection : The folder storing the auto-generated source code for Object Detection in TypeScript +
(3) Segmentation : The folder storing the auto-generated source code for Semantic Segmentation in TypeScript +

== Configure usage environment of FlatBuffers-compiler
The version of FlatBuffers-compiler uses 23.1.21.

. Download the https://github.com/google/flatbuffers/releases/download/v23.1.21/Windows.flatc.binary.zip[FlatBuffers-compiler for Windows]
. Extract the downloaded zip file to any folder by right-clicking and selecting [**Extract All**]
. Start a command prompt, move to the folder you extracted in the preceding, and make sure the version appears
+
....
> flatc.exe --version
....

[NOTE]
====
The preceding procedure assumes Windows 10. + 
To build in an environment other than Windows, install the corresponding compiler from the official page(https://github.com/google/flatbuffers/releases[FlatBuffers:Writing_schema]).
====

== Automatically generate source code for deserialize
Provides the procedure to automatically generate source code for deserialize from an FBS file.

. Prepare a FBS file on a Windows environment + 
Save the target FBS file in any directory.The sample code in this document was generated using the following FBS file. +
* link:https://github.com/SonySemiconductorSolutions/aitrios-sdk-vision-sensing-app/blob/main/tutorials/4_prepare_application/1_develop/sdk/schema/classification.fbs[classification.fbs]
* link:https://github.com/SonySemiconductorSolutions/aitrios-sdk-vision-sensing-app/blob/main/tutorials/4_prepare_application/1_develop/sdk/schema/objectdetection.fbs[objectdetection.fbs]
* semantic_segmentation.fbs (Currently not provided)

+
For instructions on how to write an FBS file, see the official page(https://google.github.io/flatbuffers/flatbuffers_guide_writing_schema.html[FlatBuffers:Writing_schema]). +


. Use FlatBuffers-compiler to generate the source code + 
In the directory where you saved the FBS file, run the following command. + 
Change the command options based on the language to create. + 
For available options, see the official page(https://google.github.io/flatbuffers/flatbuffers_guide_using_schema_compiler.html[FlatBuffers:Using_schema_compiler]).
+
....
> flatc <Language> <FBS file>
....

+
[TIP]
====
When you use the source code generation commands for TypeScript, directories and source filenames are converted to chain cases break by capital letters. +
Example 1) When "namespace TypeScript.Sample;" is set →The source code is generated in the "type-script/sample" directory. +
Example 2) When set the table name as "ObjectDetectionTop" →The source code is generated with the filename "object-detection-top.ts". 
====

== Deserialize using generated source code
Provides the procedure to deserialize using the automatically generated source code. + 
This tutorial provides each procedure, using example code for Python and TypeScript. +

=== Python
Prepare the Python execution environment and place the automatically generated source code.

==== Install the required libraries
In terminal, run the following command to install the required libraries.

....
$ pip install Flatbuffers==23.1.21
....


====  Use auto-generated Python code
Using the `**sample/Python/ObjectDetection/decode.py**` implementation as an example, provides how to use automatically generated source code in Python. +

==== 1. Import the necessary source code
[source, Python]
----
from src.Python.ObjectDetection.SmartCamera import ObjectDetectionTop
from src.Python.ObjectDetection.SmartCamera import BoundingBox
from src.Python.ObjectDetection.SmartCamera import BoundingBox2d
----

==== 2. Decode inference results in Base64
[source, Python]
----
buf_decode = base64.b64decode(buf['Inferences'][0]['O'])
----
The inference results you receive from "**Console for AITRIOS**" have been encoded in Base64 after serialize, so you need to decode. + 
Load JSON-formatted data into the `**buf**`. + 
Because a Key['O'] in the loaded JSON will be deserialized, decode if there is a Key['O'].

==== 3.Deserialize

[source, Python]
----
ppl_out = ObjectDetectionTop.ObjectDetectionTop.GetRootAsObjectDetectionTop(buf_decode, 0)
----
In the preceding source code of the `**decode.py**`, you can get the deserialized object. + 
Call the `**GetRootAsObjectDetectionTop(buf_decode, 0)**` method to the table specified by the `**root_type**` in the FBS file.

==== 4.Get inference results from deserialized data
[source, Python]
----
obj_data = ppl_out.Perception()
res_num = obj_data.ObjectDetectionListLength()
print('NumOfDetections:' + str(res_num))

# generate json
buf['Inferences'][0].pop('O')
for i in range(res_num):
    obj_list = obj_data.ObjectDetectionList(i) 
        buf['Inferences'][0][str(i + 1)] = {}
        buf['Inferences'][0][str(i + 1)]['class_id'] = obj_list.ClassId()
        buf['Inferences'][0][str(i + 1)]['score'] = round(obj_list.Score(), 6)

----
In the preceding source code of the `**decode.py**`, you can get inference results from the deserialized data. + 
The structure of the object is defined in the FBS file. + 
Get objects along the structure defined in the FBS file and access inference results. + 
Call the `**Perception()**` from the object `**ppl_out**` of the type `**ObjectDetectionTop**` to get the object `**obj_data**` of the type `**ObjectDetectionData**`. + 
Call the `**ObjectDetectionList(i)**` of the `**obj_data**` to get the object `**obj_list**` of the type `**GeneralObject**`. + 
You can get an inference result by getting the `**obj_list**` and calling the function corresponding to the inference result you want to get. + 
The definition of function names, class names, and field names depends on the FBS file used to generate the source code.



=== TypeScript
Prepare the TypeScript execution environment and place the automatically generated source code.

==== Install the required libraries
In terminal, run the following command to install the required libraries.

....
$ npm install flatbuffers@23.1.21
....

FlatBuffers is imported in the automatically generated source code for deserialize, so it must be installed beforehand.

====  Use auto-generated TypeScript code
Using the `**sample/TypeScript/ObjectDetection/decode.ts**` implementation as an example, provides how to use the automatically generated source code in TypeScript.

==== 1. Import the necessary source code
[source, TypeScript]
----
import { SmartCamera } from '../../../src/TypeScript/ObjectDetection/objectdetection'
----

==== 2. Decode inference results in Base64
[source, TypeScript]
----
// Base64 decode
let decodedData:Buffer
if ('O' in resultJson.Inferences[0]) {
  decodedData = Buffer.from(resultJson.Inferences[0].O, 'base64')
} else {
  console.log('not inference result in this data')
  fs.writeFileSync('./decoded_result_ObjectDetection.json', JSON.stringify(resultJson, null, 4))
  console.log('write file : decoded_result_ObjectDetection.json')
  return
}
----
The inference results you receive from "**Console for AITRIOS**" have been encoded in Base64 after serialize, so you need to decode. + 
Load JSON-formatted data into the `**decodedData**`. + 
Because a Key['O'] in the loaded JSON will be deserialized, decode if there is a Key['O'].

==== 3.Deserialize

[source, TypeScript]
----
const pplOut = SmartCamera.ObjectDetectionTop.getRootAsObjectDetectionTop(new flatbuffers.ByteBuffer(decodedData))
----
In the preceding source code of the `**decode.ts**`, you can get the deserialized object. + 
Call the `**getRootAsObjectDetectionTop(new flatbuffers.ByteBuffer(decodedData))**` method to the table specified by the `**root_type**` in the FBS file. + 
When passing data to the automatically generated code, it must be converted to the ByteBuffer type provided in the FlatBuffers library.

==== 4. Get deserialized data

[source, TypeScript]
----
const readObjData = pplOut.perception()
const resNum = readObjData.objectDetectionListLength()
console.log('NumOfDetections:' + String(resNum))

// generate JSON
delete resultJson.Inferences[0].O
for (let i = 0; i < resNum; i++) {
  const objList = readObjData.objectDetectionList(i)
  const res : Inference = {
    class_id: Number(objList.classId()),
    score: Math.round(Number(objList.score()) * 1000000) / 1000000
  }
  const inferenceKey = String(i + 1)
  resultJson.Inferences[0][inferenceKey] = res
}

----
In the preceding source code of the `**decode.ts**`, you can get inference results from the deserialized data. + 
The structure of the object is defined in the FBS file. + 
Get objects along the structure defined in the FBS file and access inference results. + 
Call the `**perception()**` from the `**pplOut**` of the class `**ObjectDetectionTop**` to get the `**readObjData**` of the class `**ObjectDetectionData**`. + 
Call the `**objectDetectionList(i)**` of the `**readObjData**` to get the instance `**objList**` of the class `**GeneralObject**`. + 
You can get an inference result by getting the `**objList**` and calling the function corresponding to the inference result you want to get. + 
The definition of function names, class names, and field names depends on the FBS file used to generate the source code.

== Run the sample code
You can see the behavior of deserializing the inference results by using the sample code stored under the sample directory. + 
There is the `**<AI model>_encoded.json**` under the sample/directory for the input information to deserialize. + 
The result is a JSON file in the repository root directory with the filename `**decoded_result_<AI model>.json**`.

=== Run the Python sample code
Run the following command in the repository root directory.

. Prepare environment
+
....
$ pip install -r sample/Python/requirements.txt
....
. Run the command
+
....
$ python sample/Python/<AI model>/decode.py
....
+
After running the command, the terminal will display the following and produce a `**decoded_result_<AI model>.json**` with deserialized information.
+
....
NumOfDetections:2
write file : decoded_result_<AI model>.json
....

=== Run the TypeScript sample code
Run the following command in the repository root directory.

. Prepare environment
+
....
$ npm install
....
. Run the command
+
....
$ npm run <AI model>
....
+

After running the command, the terminal will display the following and produce a `**decoded_result_<AI model>.json**` with deserialized information.
+
....
NumOfDetections:2
write file : decoded_result_<AI model>.json
....

== Reference materials

=== Description of the stored auto-generated code
[NOTE]
====
The FBS file used for generation defines objects based on the AITRIOS standard format. + 
Therefore, it is only available for AITRIOS standard output inference results.
====

The code stored under the src directory is the deserialize code generated automatically by the command in the "Automatically generate source code for deserialize", with modifications to make the sample work. + 
Therefore, you can deserialize by incorporating the stored code directly into the project. +

==== Description of the data that can be gotten by each function
==== Object Detection
|===
|Function |Environment |Description

|ObjectDetectionListLength/objectDetectionListLength
|Python/TypeScript
|Number of inference results in the serialized data

|ObjectDetectionList/objectDetectionList
|Python/TypeScript
|List of inference results

|ClassId/classId
|Python/TypeScript
|Labels in inference results

|Score/score
|Python/TypeScript
|Confidence in inference results

|Boundingbox2d/boundingbox2d
|Python/TypeScript
|Coordinate group on the image of the detected object

|Left/left
|Python/TypeScript
|x-coordinate of the start point of the detected object

|Top/top
|Python/TypeScript
|y-coordinate of the start point of the detected object

|Right/right
|Python/TypeScript
|x-coordinate of the end point of the detected object

|Bottom/bottom
|Python/TypeScript
|y-coordinate of the end point of the detected object
|===
==== Classification
|===
|Function |Environment |Description

|ClassificationListLength/classificationListLength
|Python/TypeScript
|Number of inference results in the serialized data

|ClassificationList/classificationList
|Python/TypeScript
|List of inference results

|ClassId/classId
|Python/TypeScript
|Labels in inference results

|Score/score
|Python/TypeScript
|Confidence in inference results
|===
==== Segmentation
|===
|Function |Environment |Description

|Height/height
|Python/TypeScript
|Height of the image (pixel)

|Width/width
|Python/TypeScript
|Width of the image (pixel)

|classIdMap
|TypeScript
|Position on the image (pixel)

|classIdMapLength
|TypeScript
|Number of pixels in the image

|ClassIdMapAsNumpy
|Python
|List of positions on the image

|NumClassId/numClassId
|Python/TypeScript
|Number of detected objects

|scoreMap
|TypeScript
|Confidence in inference results

|scoreMapLength
|TypeScript
|Length of the list of inference results

|ScoreMapAsNumpy
|Python
|List of confidence in inference results

|===
== Remarks/Restrictions
None
